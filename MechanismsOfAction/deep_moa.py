# -*- coding: utf-8 -*-
"""Deep MoA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cWIW_wcVQ0n6vCMuuv0B1cIUsNdGGCdQ
"""

# Commented out IPython magic to ensure Python compatibility.
# import essentials
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import os
import random
import pickle
from time import time
import datetime
 
# %matplotlib inline

from google.colab import drive
drive.mount('/content/gdrive')
from google.colab import files
import json

def seed_everything(seed=0):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    
seed = 69
seed_everything(seed)

train = pd.read_csv('/content/gdrive/My Drive/input/moa/data/train_features.csv')
target = pd.read_csv('/content/gdrive/My Drive/input/moa/data/train_targets_scored.csv')
print(f'train shape: {train.shape}')
print(f'target shape: {target.shape}')
train.head()

def clean_df(_df) :
    df = _df.copy()
    df = df.drop(columns=['sig_id'])
    df['vehicle'] = df.cp_type.apply(
        lambda x: x == 'ctl_vehicle'
    ).astype(np.int8)
    df.drop(columns=['cp_type'],inplace=True)
    df['d2'] = df.cp_dose.apply(
        lambda x: x == 'D2'
    ).astype(np.int8)
    df.drop(columns=['cp_dose'],inplace=True)
    return df

X = clean_df(train)
Y = target.iloc[:,1:]

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from tensorflow.keras.layers import Dense,Dropout,Conv2D,BatchNormalization
from tensorflow.keras.optimizers import Adam
import tensorflow_addons as tfa
from tensorflow_addons.layers import WeightNormalization
from tensorflow.keras.metrics import BinaryCrossentropy

from sklearn.model_selection import train_test_split
from sklearn.metrics import log_loss

X_train,X_test,y_train,y_test = train_test_split(X,Y,random_state=seed)

def build_model() :
    model = Sequential([
        BatchNormalization(),
        WeightNormalization(Dense(2048,activation='relu')),
        Dropout(.4),
        
        BatchNormalization(),
        WeightNormalization(Dense(1028,activation='relu')),
        Dropout(.2),

        BatchNormalization(),
        WeightNormalization(Dense(512,activation='relu')),
        Dropout(.2),

        BatchNormalization(),
        WeightNormalization(Dense(206,activation='sigmoid')),
        Dropout(.2),
    ])

    model.compile(
        optimizer='adam',
        loss='binary_crossentropy'
    )

    return model

model = build_model()

model.fit(X_train,y_train,epochs=20)

model.evaluate(X_train,y_train)
model.evaluate(X_test,y_test)

y_pred = model.predict(X_test)

def get_log_loss(Y_true,Y_pred) :

    score = 0

    assert Y_pred.shape == Y_true.shape

    for col in range(Y_pred.shape[1]) :
        score += log_loss(Y_true[:,col],Y_pred[:,col],labels=[0,1])
    return score / Y_pred.shape[1]

get_log_loss(y_test.values,y_pred)

def build_model() :
    model = Sequential([
        BatchNormalization(),
        WeightNormalization(Dense(2048,activation='relu')),
        Dropout(.4),
        
        BatchNormalization(),
        WeightNormalization(Dense(1028,activation='relu')),
        Dropout(.2),

        BatchNormalization(),
        WeightNormalization(Dense(512,activation='relu')),
        Dropout(.2),

        BatchNormalization(),
        WeightNormalization(Dense(206,activation='sigmoid')),
        Dropout(.2),
    ])

    model.compile(
        optimizer='adam',
        loss='binary_crossentropy'
    )

    return model

X_train,X_test,y_train,y_test = train_test_split(X,Y,random_state=seed+1)
model2 = build_model2()
model2.fit(X_train,y_train,epochs=18)

model2.evaluate(X_train,y_train)
model2.evaluate(X_test,y_test)

butt = model2.evaluate(X_test,y_test)
print(butt)

