# -*- coding: utf-8 -*-
"""moapredict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13_MPalojUWMApsPSrZbmdYv3rUZEJaci
"""

# Commented out IPython magic to ensure Python compatibility.
# import essentials
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# %matplotlib inline

seed = 69
np.random.seed(seed)

train = pd.read_csv('train_features.csv')
target = pd.read_csv('train_targets_scored.csv')

print(f'train shape: {train.shape}')
print(f'target shape: {target.shape}')
train.head()

print(target.shape)
target.head()

clean_train = train.drop(columns=['sig_id'])
clean_train['vehicle'] = train.cp_type.apply(
    lambda x: x == 'ctl_vehicle'
).astype(np.int8)
clean_train.drop(columns=['cp_type'],inplace=True)
clean_train.vehicle.value_counts()

clean_target = target.drop(columns=['sig_id'])

train.cp_time.value_counts()

train.cp_dose.value_counts()

clean_train['d2'] = train.cp_dose.apply(
    lambda x: x == 'D2'
).astype(np.int8)
clean_train.drop(columns=['cp_dose'],inplace=True)
clean_train.shape

# For a more general case, we could implement this code:
from sklearn.preprocessing import LabelEncoder
def convert_cat_cols(df :pd.DataFrame) :
    """

    """
    le = LabelEncoder()
    new_df = df.copy()
    for col in df.keys() :
        if np.issubdtype(df[col].dtype, np.number) : continue
        # check if it's a unique non-numeric identifier
        if df[col].nunique() == df.shape[0] : 
            new_df.drop(columns=[col],inplace=True)
        # it isnt a number or a unique identifier, so convert it to a label
        new_df[col] = le.fit_transform(df[col])
    return new_df

# that cleans up the X matrix. Now for the Y matrix
convert_cat_cols(train).head()

from sklearn.model_selection import train_test_split

# split into train/test sets
X_train,X_test,Y_train,Y_test = \
    train_test_split(clean_train,clean_target,shuffle=True,random_state=seed)

# let's check how unbalanced our classes are
Y_train.mean().mean()

# very unbalanced. We may use metrics other than accuracy to judge our interim results
# however, the final judgment is based on log loss of liklihood, so we will ultimately 
# compare this to a log loss estimate

y_train,y_test = Y_train.iloc[:,0],Y_test.iloc[:,0]

'''
corrmat = pd.concat([clean_train,target.iloc[:,1]],axis=1).corr(method='spearman')['5-alpha_reductase_inhibitor']\
    .drop('5-alpha_reductase_inhibitor').sort_values(ascending=False)
fig = plt.figure(figsize=(10,12))
plt.title('Spearman correlation with first target')
fig = sns.barplot(y=corrmat.index,x=corrmat.values,
                  palette='twilight_shifted',orient='h')
'''

# import our evaluation methods
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import confusion_matrix, log_loss, roc_auc_score

# import oversampling techniques
from imblearn.over_sampling import SMOTE

def score(y_test,y_pred,method='log_loss') :
    if method == 'log_loss' : return log_loss(y_test,y_pred)
    if method == 'roc' : return roc_auc_score(y_test,y_pred)

# import our models
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# import our ensambling methods
from imblearn.pipeline import Pipeline
from sklearn.ensemble import StackingClassifier
from sklearn.multioutput import MultiOutputClassifier

def make_pipeline(clf) :
    pipe = Pipeline([
        ('scaler',StandardScaler()),
        #('sampling',SMOTE()),
        ('clf',clf)
    ])
    return pipe

def pipe_gridsearch(pipe,param_grid=None) :
    pass

clf = LGBMClassifier()
pipe = make_pipeline(clf)
pipe.fit(X_train,y_train)
y_pred = pipe.predict_proba(X_test)

log_loss(y_test,y_pred)
poop = 0

def make_pipe_dict(clf,X_train=X_train,X_test=X_test,Y_train=Y_train,Y_test=Y_test) :
    pipe_dict = {}
    scores = 0
    _X_train,_X_test,_Y_train,_Y_test = X_train.copy(),X_test.copy(),Y_train.copy(),Y_test.copy()
    for col in Y_train.keys() :
        y_train, y_test = _Y_train[col],_Y_test[col]
        pipe = make_pipeline(clf)
        pipe.fit(_X_train,y_train)
        y_pred = pipe.predict(_X_test)
        scores += log_loss(y_test,y_pred,labels=[0,1])
        pipe_dict[col] = pipe
    scores /= len(_Y_train.keys())
    print(f'Score: {scores}')
    return pipe_dict

from time import time

t = time()
lgbm = LGBMClassifier()
pipe_dict = make_pipe_dict(lgbm)
pipe_dict

time() - t

Y_train.sum().sort_values(ascending=True)


from sklearn.model_selection import GridSearchCV

def make_grid_pipe(clf,y,param_grid=None) :
    num_samples = y.sum() * .8 - 1
    pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('sampling', SMOTE(k_neighbors=max(5, int(y.sum() * .8 - 1)),
                           random_state=seed,sampling_strategy='minority')),
        ('clf', clf)
    ])

    poop = XGBClassifier()
    if param_grid is None :
        param_grid = {
            'max_depth':[-1,3,6,9],
            'bagging_seed':[seed],
            'colsample_bytree':[1,.9,.7],
            'lambda':[1,1.2,1.4],
            'scale_pos_weight':[1,y.shape[0]/y.sum()]
        }

    model = GridSearchCV(estimator=pipe,
                       param_grid=param_grid,
                       cv=3,scoring='neg_log_loss')

    return model